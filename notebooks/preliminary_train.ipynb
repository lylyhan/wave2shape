{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv1D, AveragePooling1D, Conv2D, MaxPooling2D,ReLU\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model #save and load models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "import IPython.display as ipd\n",
    "from kymatio import Scattering1D\n",
    "import hitdifferentparts\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pescador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify if using GPU\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scattering order one\n",
    "def getsc_new(y,J,Q_num,order):\n",
    "    \"\"\"\n",
    "    this function outputs scattering transform of a time-domain signal.\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    scattering = Scattering1D(J = J,shape=(N,), Q = Q_num, max_order=order)\n",
    "    Sy = scattering(torch.Tensor(y))\n",
    "    return Sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./train_param.csv\")\n",
    "df_test = pd.read_csv(\"./test_param.csv\")\n",
    "df_val = pd.read_csv(\"./val_param.csv\")\n",
    "df_full = pd.read_csv(\"./diffshapes_param.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of the physical parameters\n",
    "params = df_train.values[:,1:-1]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(params)\n",
    "train_params_normalized = scaler.transform(params)\n",
    "test_params_normalized = scaler.transform(df_test.values[:,1:-1])\n",
    "val_params_normalized = scaler.transform(df_val.values[:,1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_sampler(df,params_normalized,idx,path_to_folder,J,Q,order):\n",
    "    \"\"\"\n",
    "    output a {input, ground truth} pair for the designated audio sample\n",
    "    \"\"\"\n",
    "    i=idx\n",
    "    y=np.array(params_normalized[i,:]).reshape((5,)) #df.values[i,1:-1]\n",
    "    path_to_audio = os.path.join(path_to_folder,str(df.values[i,0])+\"_sound.wav\") \n",
    "    x,fs=librosa.load(path_to_audio)\n",
    "    Sy = getsc_new(x,J,Q,order)\n",
    "    m,n = Sy.shape\n",
    "    Sy2 = np.array(Sy).reshape((n,m))\n",
    "    \n",
    "    while True:\n",
    "        yield {'input': Sy2,'y': y}\n",
    "\n",
    "        \n",
    "def data_generator(df, params_normalized, path_to_folder, J, Q, order, batch_size, idx, active_streamers,\n",
    "                        rate, random_state=12345678):\n",
    "    \"\"\"\n",
    "    use streamers to output a batch of {input groundtruth} pairs. \n",
    "    \"\"\"\n",
    "    seeds = []\n",
    "    for i in idx:\n",
    "        streamer = pescador.Streamer(feature_sampler, df, params_normalized, i,path_to_folder,J,Q,order)\n",
    "        seeds.append(streamer)\n",
    "\n",
    "    # Randomly shuffle the seeds\n",
    "    random.shuffle(seeds)\n",
    "\n",
    "    mux = pescador.StochasticMux(seeds, active_streamers, rate=rate, random_state=random_state)\n",
    "   \n",
    "    if batch_size == 1:\n",
    "        return mux\n",
    "    else:\n",
    "        return pescador.maps.buffer_stream(mux, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first run with small number of training\n",
    "epochs=12\n",
    "batch_size=32\n",
    "random_state=12345678\n",
    "active_streamers=1024\n",
    "path_to_train = \"/scratch/hh2263/drum_data/train/\"\n",
    "path_to_test = \"/scratch/hh2263/drum_data/test/\"\n",
    "J = 8\n",
    "Q = 1\n",
    "order = 2 # remember to go to order 2 eventually\n",
    "train_idx = np.arange(0,1000,1) #df_train.values[:1000,0]\n",
    "test_idx = np.arange(0,300,1) #df_test.values[:300,0]\n",
    "train_batches=data_generator(df_train,train_params_normalized, path_to_train,J, Q, order, batch_size, train_idx,active_streamers,rate=64,random_state=random_state)\n",
    "test_batches=data_generator(df_test,test_params_normalized, path_to_test,J, Q, order, batch_size, test_idx,active_streamers,rate=64,random_state=random_state)\n",
    "steps_per_epoch = len(train_idx) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = random.choice(os.listdir(path_to_train))\n",
    "rand_audio = os.path.join(path_to_train,fname)\n",
    "y,sr = librosa.load(rand_audio)\n",
    "Sy = getsc_new(torch.Tensor(y),J,Q,order).T\n",
    "nrow, ncol = Sy.shape \n",
    "naudio = batch_size         # number of images in batch\n",
    "nchan_in = 1       # number of input channels.  1 since it is BW\n",
    "#input_shape = (nrow,ncol,nchan_in)  # input shape of 1 image\n",
    "input_shape = Sy.shape\n",
    "batch_shape = (naudio,nrow,ncol,nchan_in)  # shape of image batch\n",
    "#x = Sy.reshape(batch_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 43]) (32, 128, 43, 1)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape,batch_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv1D)               (None, 128, 16)           5520      \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv1D)               (None, 32, 16)            2064      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv1D)               (None, 8, 16)             2064      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv1D)               (None, 2, 16)             2064      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1, 16)             64        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 13,445\n",
      "Trainable params: 13,285\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "kernel_size = (8,)\n",
    "nchan_out = 16\n",
    "\n",
    "K.clear_session()\n",
    "model=Sequential()\n",
    "model.add(Conv1D(input_shape=input_shape, filters=nchan_out,\n",
    "                 kernel_size=kernel_size,activation= \"relu\", padding=\"same\",name='conv1'))\n",
    "model.add(AveragePooling1D(pool_size=(4,)))\n",
    "model.add(Conv1D(filters=16,\n",
    "                 kernel_size=kernel_size,activation= \"relu\", padding=\"same\",name='conv2' ))\n",
    "model.add(AveragePooling1D(pool_size=(4,)))\n",
    "model.add(Conv1D(filters=16,\n",
    "                 kernel_size=kernel_size,activation= \"relu\", padding=\"same\",name='conv3' ))\n",
    "model.add(AveragePooling1D(pool_size=(4,)))\n",
    "model.add(Conv1D(filters=16,\n",
    "                 kernel_size=kernel_size,activation= \"relu\", padding=\"same\",name='conv4' ))\n",
    "model.add(AveragePooling1D(pool_size=(2,)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#what activation should be chosen for last layer, for regression problem? should be a linear function\n",
    "model.add(Dense(5, activation='linear')) #output layer that corresponds to the 5 physical parameters.\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "output_dir = \"../output/\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "model_filepath = os.path.join(output_dir, 'model.h5')\n",
    "log_filepath = os.path.join(output_dir, 'train_log.csv')\n",
    "\n",
    "callbacks = []\n",
    "callbacks.append(EarlyStopping(patience=10))\n",
    "callbacks.append(ModelCheckpoint(model_filepath, save_best_only=True))\n",
    "callbacks.append(CSVLogger(log_filepath))\n",
    "\n",
    "print(\"Fitting model.\")\n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 31 steps, validate for 1024 steps\n",
      "Epoch 1/12\n",
      "31/31 [==============================] - 788s 25s/step - loss: 0.1431 - accuracy: 0.6028 - val_loss: 0.1206 - val_accuracy: 0.3282\n",
      "Epoch 2/12\n",
      " 2/31 [>.............................] - ETA: 27:37 - loss: 0.0884 - accuracy: 0.7969"
     ]
    }
   ],
   "source": [
    "#preliminary test\n",
    "hist = model.fit(\n",
    "        pescador.maps.keras_tuples(train_batches, 'input', 'y'),\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=2,\n",
    "        validation_data=pescador.maps.keras_tuples(test_batches, 'input', 'y'),\n",
    "        validation_steps=1024,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(model_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
