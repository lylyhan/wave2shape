{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import torch\n",
    "from kymatio.torch import Scattering1D\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import cnn\n",
    "import ftm_ver2 as ftm2\n",
    "import hcqt\n",
    "import soundfile as sf\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv1D, AveragePooling1D, Conv2D, MaxPooling2D,ReLU,AveragePooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model #save and load models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import IPython.display as ipd\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshape different features\n",
    "1. CQT\n",
    "2. VQT\n",
    "3. HCQT\n",
    "4. Time scattering 1st order\n",
    "5. Time scattering 2nd order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set consistent parameters for different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hcqt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m b \u001b[38;5;241m=\u001b[39m q\n\u001b[1;32m      8\u001b[0m fmin \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.4\u001b[39m\u001b[38;5;241m*\u001b[39msr\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m-\u001b[39mj)\n\u001b[0;32m----> 9\u001b[0m comp_hcqt \u001b[38;5;241m=\u001b[39m \u001b[43mhcqt\u001b[49m\u001b[38;5;241m.\u001b[39mHCQT(sr,bins_per_octave\u001b[38;5;241m=\u001b[39mb,harmonics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     10\u001b[0m                  n_octaves\u001b[38;5;241m=\u001b[39mn_oct\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,f_min\u001b[38;5;241m=\u001b[39mfmin,hop_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hcqt' is not defined"
     ]
    }
   ],
   "source": [
    "j = 14\n",
    "q = 1\n",
    "N = 2**16\n",
    "sr = 22050\n",
    "n_oct = j\n",
    "t = 2**11\n",
    "b = q\n",
    "fmin = 0.4*sr*2**(-j)\n",
    "comp_hcqt = hcqt.HCQT(sr,bins_per_octave=b,harmonics=[0.5,1,2,3,4,5],\n",
    "                 n_octaves=n_oct-2,f_min=fmin,hop_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesc = Scattering1D(\n",
    "        J = j, #scale, how big the biggest time support (for the lowest freqeuncy), where center frequencies are?\n",
    "        shape = (N, ),\n",
    "        Q = q,\n",
    "        T=t, \n",
    "        max_order=1\n",
    "        )\n",
    "timesc2 = Scattering1D(\n",
    "        J = j, #scale, how big the biggest time support (for the lowest freqeuncy), where center frequencies are?\n",
    "        shape = (N, ),\n",
    "        Q = q,\n",
    "        T=t, \n",
    "        max_order=2\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1,sr = sf.read(\"/home/han/data/drum_data/val/22222_sound.wav\")\n",
    "y1 = torch.Tensor(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cqt = librosa.cqt(y1.numpy(),sr=sr,n_bins=n_oct*b,fmin=fmin,hop_length=256,bins_per_octave=b) \n",
    "v_cqt = np.abs(librosa.vqt(y1.numpy(),sr=sr,n_bins=n_oct*b,fmin=fmin,gamma=None,bins_per_octave=b,hop_length=256))\n",
    "h_cqt = comp_hcqt.compute_hcqt(y1.numpy(),sr)\n",
    "sc = timesc(y1) #after 2**j averaging window\n",
    "sc2 = timesc2(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14, 257),\n",
       " (14, 256),\n",
       " (6, 12, 257),\n",
       " torch.Size([16, 32]),\n",
       " torch.Size([118, 32]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cqt.shape,v_cqt.shape,h_cqt.shape,sc.shape,sc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "data_dir = \"/home/han/data/drum_data/\"\n",
    "csv_path = os.path.join(data_dir,\"annotations\",\"train_param_v2.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "sample_ids = df.values[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wave2shape model\n",
    "1. fully connected CNN model\n",
    "2. #layers ~ log(# scattering coefficients $\\lambda$)\n",
    "3. input: scattering transform of each percussive sounds (number of audio N, scattering coeff $\\lambda$, time K)\n",
    "4. output: 5 physical parameters $\\theta = {\\tau, p, D, \\alpha, w}$\n",
    "\n",
    "what invariance do i want?\n",
    "1. equivariance to pitch shift, so no pooling along frequency axis\n",
    "2. invariant to time shift, can be pooled along time axis. maximum invariance, half of the audio length..\n",
    "3. equivariance to time decay.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 32, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 23:40:12.707865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 23:40:13.022088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 23:40:13.023884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 23:40:13.042269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 23:40:13.043759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 23:40:13.045192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 23:40:16.439856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 23:40:16.440676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 23:40:16.441457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 23:40:16.449741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9599 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 16, 32, 1)]       0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 32, 1)        4         \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 16, 32, 128)       768       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 16, 8, 128)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv1_2 (Conv1D)            (None, 16, 8, 64)         24640     \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 16, 2, 64)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 2, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1_3 (Conv1D)            (None, 16, 2, 64)         12352     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 2, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1_4 (Conv1D)            (None, 16, 2, 8)          520       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 2, 8)         32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,857\n",
      "Trainable params: 55,455\n",
      "Non-trainable params: 402\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "y = ftm2.getsounds_imp_linear_nonorm(10,10,0.4,0.6,0.03,0.3,100*2*np.pi,\n",
    "                                 0.02,0.03,np.pi,1,44100)\n",
    "S = timesc(torch.Tensor(y))\n",
    "nrow, ncol = S.shape \n",
    "naudio = 1         # number of audio in batch\n",
    "nchan_in = 1       # number of input channels. \n",
    "input_shape = (nrow,ncol,nchan_in)  # input shape of 1 image\n",
    "batch_shape = (naudio,nrow,ncol,nchan_in)  # shape of image batch\n",
    "\n",
    "S = S.reshape(batch_shape)\n",
    "print(S.shape)\n",
    "#this way convolution is done along time axis, each kernel looks at all frequencies at once\n",
    "S_input_shape = (S.shape[1],S.shape[2],nchan_in) #f,t,#channels\n",
    "\n",
    "S_input = keras.layers.Input(shape=S_input_shape)\n",
    "kernel_size = (8,)\n",
    "nchan_out = 16\n",
    "\n",
    "x = BatchNormalization()(S_input)\n",
    "x = Conv1D(filters=128,\n",
    "        kernel_size=(5,), padding=\"same\",name='conv1')(x) #convolve along the last dimension before #channel\n",
    "x = AveragePooling2D(pool_size=(1,4),padding=\"valid\")(x)\n",
    "x = Conv1D(filters=64,\n",
    "          kernel_size=(3,),padding=\"same\",name=\"conv1_2\")(x)\n",
    "x = AveragePooling2D(pool_size=(1,4),padding=\"valid\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(filters=64,\n",
    "          kernel_size=(3,),padding=\"same\",name=\"conv1_3\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(filters=8,\n",
    "          kernel_size=(1,),padding=\"same\",name=\"conv1_4\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "#what activation should be chosen for last layer, for regression problem? should be a linear function\n",
    "x = Dense(5, activation=\"linear\")(x)\n",
    "#x = AveragePooling2D(pool_size=4,padding=\"valid\")(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=[S_input], outputs=x)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 32])\n",
      "torch.Size([1, 16, 32, 1])\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 32, 16)]          0         \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 32, 16)           64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 32, 128)           10368     \n",
      "                                                                 \n",
      " average_pooling1d_4 (Averag  (None, 8, 128)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " conv1_2 (Conv1D)            (None, 8, 64)             24640     \n",
      "                                                                 \n",
      " average_pooling1d_5 (Averag  (None, 2, 64)            0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 2, 64)            256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1_3 (Conv1D)            (None, 2, 64)             12352     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 2, 64)            256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1_4 (Conv1D)            (None, 2, 8)              520       \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 2, 8)             32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                1088      \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,157\n",
      "Trainable params: 49,725\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "y = ftm2.getsounds_imp_linear_nonorm(10,10,0.4,0.6,0.03,0.3,100*2*np.pi,\n",
    "                                 0.02,0.03,np.pi,1,44100)\n",
    "S = timesc(torch.Tensor(y))\n",
    "nrow, ncol = S.shape \n",
    "print(S.shape)\n",
    "naudio = 1         # number of audio in batch\n",
    "nchan_in = 1       # number of input channels. \n",
    "input_shape = (nrow,ncol,nchan_in)  # input shape of 1 image\n",
    "batch_shape = (naudio,nrow,ncol,nchan_in)  # shape of image batch\n",
    "\n",
    "S = S.reshape(batch_shape)\n",
    "print(S.shape)\n",
    "#this way convolution is done along time axis, each kernel looks at all frequencies at once\n",
    "S_input_shape = (S.shape[2],S.shape[1]) #f,t,#channels\n",
    "\n",
    "S_input = keras.layers.Input(shape=S_input_shape)\n",
    "kernel_size = (8,)\n",
    "nchan_out = 16\n",
    "\n",
    "x = BatchNormalization()(S_input)\n",
    "x = Conv1D(filters=128,\n",
    "        kernel_size=(5,), padding=\"same\",name='conv1')(x) #convolve along the last dimension before #channel\n",
    "x = AveragePooling1D(pool_size=(4,),padding=\"valid\")(x)\n",
    "x = Conv1D(filters=64,\n",
    "          kernel_size=(3,),padding=\"same\",name=\"conv1_2\")(x)\n",
    "x = AveragePooling1D(pool_size=(4,),padding=\"valid\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(filters=64,\n",
    "          kernel_size=(3,),padding=\"same\",name=\"conv1_3\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(filters=8,\n",
    "          kernel_size=(1,),padding=\"same\",name=\"conv1_4\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "#what activation should be chosen for last layer, for regression problem? should be a linear function\n",
    "x = Dense(5, activation=\"linear\")(x)\n",
    "#x = AveragePooling2D(pool_size=4,padding=\"valid\")(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=[S_input], outputs=x)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 160, 257)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 160, 257, 6)]     0         \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 160, 257, 6)      24        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 160, 257, 128)     19328     \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 160, 16, 128)     0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 160, 16, 64)       73792     \n",
      "                                                                 \n",
      " average_pooling2d_6 (Averag  (None, 160, 4, 64)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 160, 4, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 160, 4, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 160, 4, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv4 (Conv2D)              (None, 160, 4, 8)         520       \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 160, 4, 8)        32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 5120)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                327744    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 459,461\n",
      "Trainable params: 459,049\n",
      "Non-trainable params: 412\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "h_cqt = comp_hcqt.compute_hcqt(y1.numpy(),sr)y = ftm2.getsounds_imp_linear_nonorm(10,10,0.4,0.6,0.03,0.3,100*2*np.pi,\n",
    "                                 0.02,0.03,np.pi,1,44100)\n",
    "S = timesc(torch.Tensor(y))\n",
    "nrow, ncol = S.shape \n",
    "naudio = 1         # number of audio in batch\n",
    "nchan_in = 1       # number of input channels. \n",
    "input_shape = (nrow,ncol,nchan_in)  # input shape of 1 image\n",
    "batch_shape = (naudio,nrow,ncol,nchan_in)  # shape of image batch\n",
    "\n",
    "S = S.reshape(batch_shape)\n",
    "print(S.shape)\n",
    "#this way convolution is done along time axis, each kernel looks at all frequencies at once\n",
    "S_input_shape = (S.shape[1],S.shape[2],nchan_in) #f,t,#channels\n",
    "\n",
    "S_input = keras.layers.Input(shape=S_input_shape)\n",
    "kernel_size = (8,)\n",
    "nchan_out = 16\n",
    "\n",
    "x = BatchNormalization()(S_input)\n",
    "x = Conv1D(filters=128,\n",
    "        kernel_size=(5,), padding=\"same\",name='conv1')(x) #convolve along the last dimension before #channel\n",
    "x = AveragePooling2D(pool_size=(1,4),padding=\"valid\")(x)\n",
    "x = Conv1D(filters=64,\n",
    "          kernel_size=(3,),padding=\"same\",name=\"conv1_2\")(x)\n",
    "x = AveragePooling2D(pool_size=(1,4),padding=\"valid\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(filters=64,\n",
    "          kernel_size=(3,),padding=\"same\",name=\"conv1_3\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(filters=8,\n",
    "          kernel_size=(1,),padding=\"same\",name=\"conv1_4\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "#what activation should be chosen for last layer, for regression problem? should be a linear function\n",
    "x = Dense(5, activation=\"linear\")(x)\n",
    "#x = AveragePooling2D(pool_size=4,padding=\"valid\")(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=[S_input], outputs=x)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "print(h_cqt.shape)\n",
    "nchan_in,nrow, ncol = h_cqt.shape \n",
    "naudio = 1         # number of images in batch\n",
    "input_shape = (nrow,ncol,nchan_in)  # input shape of 1 image\n",
    "batch_shape = (naudio,nrow,ncol,nchan_in)  # shape of image batch\n",
    "h_cqt = h_cqt.reshape(batch_shape)\n",
    "#2D convolution is done along time and frequency axis, each kernel looks at 6 channels at once\n",
    "hcqt_input_shape = (h_cqt.shape[1],h_cqt.shape[2],h_cqt.shape[3]) \n",
    "\n",
    "hcqt_input = keras.layers.Input(shape=hcqt_input_shape)\n",
    "nchan_out = 16\n",
    "x = BatchNormalization()(hcqt_input)\n",
    "x = Conv2D(filters=128,\n",
    "        kernel_size=(5,5), padding=\"same\",name='conv1')(x) #convolve along the last dimension before #channel\n",
    "x = AveragePooling2D(pool_size=(1,16),padding=\"valid\")(x)\n",
    "x = Conv2D(filters=64,\n",
    "        kernel_size=(3,3), padding=\"same\",name='conv2')(x)\n",
    "x = AveragePooling2D(pool_size=(1,4),padding=\"valid\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=64,\n",
    "        kernel_size=(3,3), padding=\"same\",name='conv3')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=8,\n",
    "        kernel_size=(1,1), padding=\"same\",name='conv4')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(5, activation=\"linear\")(x)\n",
    "model = Model(inputs=[hcqt_input], outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scattering1D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 257)\n",
      "(257, 192, 1) (1, 192, 257, 1)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 257, 192, 1)]     0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 257, 192, 1)      4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 257, 192, 16)      1040      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 16, 192, 16)      0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " squish (Conv2D)             (None, 16, 192, 1)        81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,125\n",
      "Trainable params: 1,123\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cqt = librosa.cqt(y1.numpy(),sr=sr,n_bins=(n_oct)*b,fmin=fmin,hop_length=256,bins_per_octave=b) \n",
    "print(cqt.shape)\n",
    "nrow, ncol = cqt.shape \n",
    "naudio = 1         # number of images in batch\n",
    "input_shape = (nrow,ncol,nchan_in)  # input shape of 1 image\n",
    "nchan_in = 1\n",
    "batch_shape = (naudio,nrow,ncol,nchan_in)  # shape of image batch\n",
    "cqt = cqt.reshape(batch_shape)\n",
    "#2D convolution is done along time and frequency axis, each kernel looks at 6 channels at once\n",
    "cqt_input_shape = (cqt.shape[2],cqt.shape[1],nchan_in)\n",
    "print(cqt_input_shape,cqt.shape)\n",
    "\n",
    "cqt_input = keras.layers.Input(shape=cqt_input_shape)\n",
    "kernel_size = (8,8) #frequency and time\n",
    "nchan_out = 16\n",
    "x = BatchNormalization()(cqt_input)\n",
    "x = Conv2D(filters=nchan_out,\n",
    "          kernel_size=kernel_size, padding=\"same\",name=\"conv2d\")(x)\n",
    "#pool time resolution to match scattering\n",
    "x = AveragePooling2D(pool_size=(16,1),strides=None, padding=\"valid\")(x) #average across 4 \n",
    "\n",
    "x = Conv2D(filters=1,kernel_size=(5,1),padding=\"same\",name=\"squish\")(x) \n",
    "model = Model(inputs=[cqt_input], outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build two experiments and move them into training scripts. start running them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. load scattering features\n",
    "2. make model\n",
    "3. randomly choose samples and train fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_789777/3307087980.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 10:13:08.750187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 10:13:08.888019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 10:13:08.888728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 10:13:10.025512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 10:13:10.026260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 10:13:10.026957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 10:13:10.027573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 9599 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#verify if using GPU\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/home/han/data/drum_data/annotations/train_param_v2.csv\")\n",
    "df_test = pd.read_csv(\"/home/han/data/drum_data/annotations/test_param_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = df_train.values[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# normalization of the physical parameters\n",
    "params = df.values[:,1:-1]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(params)\n",
    "params_normalized = scaler.transform(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import os \n",
    "\n",
    "pkl_dir = '/home/han/data/drum_data/han2022features-pkl/'\n",
    "J = 12\n",
    "Q = 1\n",
    "feature = \"scattering_o1\"\n",
    "fold_str = \"train\"\n",
    "pickle_name = \"_\".join(\n",
    "        [feature,\n",
    "         \"fold-\"+str(fold_str),\"J-\" + str(J).zfill(2), \"Q-\" + str(Q).zfill(2)]\n",
    "    )\n",
    "\n",
    "pkl_path_train = os.path.join(pkl_dir,feature,pickle_name+\".pkl\")\n",
    "pkl_train = open(pkl_path_train,'rb')\n",
    "Sy_train,y_train = pickle.load(pkl_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 12\n",
    "Q = 11\n",
    "feature = \"scattering_o1\"\n",
    "fold_str = \"val\"\n",
    "pickle_name = \"_\".join(\n",
    "        [feature,\n",
    "         \"fold-\"+str(fold_str),\"J-\" + str(J).zfill(2), \"Q-\" + str(Q).zfill(2)]\n",
    "    )\n",
    "\n",
    "pkl_path_val = os.path.join(pkl_dir,feature,pickle_name+\".pkl\")\n",
    "pkl_val = open(pkl_path_val,'rb')\n",
    "Sy_val,y_val = pickle.load(pkl_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82224, 32, 14), (82224, 5), (7776, 32, 117), (7776, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sy_train.shape,y_train.shape,Sy_val.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 11:23:44.114576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:23:44.123989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:23:44.124809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:23:44.126606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:23:44.127317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:23:44.127987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:23:44.741988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:23:44.742592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:23:44.743142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:23:44.743678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9599 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 14, 32, 1)]       0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 14, 32, 1)        4         \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 14, 32, 128)       1152      \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 8, 128)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 8, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1_2 (Conv1D)            (None, 14, 8, 64)         32832     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 8, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1_3 (Conv1D)            (None, 14, 8, 64)         16448     \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 14, 2, 64)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 2, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1_4 (Conv1D)            (None, 14, 2, 8)          520       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 14, 2, 8)         32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                14400     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,993\n",
      "Trainable params: 66,335\n",
      "Non-trainable params: 658\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import cnn\n",
    "steps_per_epoch = 50\n",
    "bs = 64\n",
    "m = bs*steps_per_epoch\n",
    "j = 12\n",
    "q = 1\n",
    "model = cnn.create_model_conv1d(j,q,Sy_train[:m,:,:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log scale training features, normalize ground truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log scale omega and p and D \n",
    "y_train = y_train.astype('float')\n",
    "for idx in [0,2,3]:\n",
    "\ty_train[:,idx] = [np.log10(i) for i in y_train[:,idx]]\n",
    "\n",
    "# normalization of the physical parameters\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(y_train)\n",
    "y_train_normalized = scaler.transform(y_train)\n",
    "\n",
    "#log scale the input\n",
    "eps = 1e-11\n",
    "Sy_train_log2 = np.log1p(((Sy_train>0)*Sy_train)/eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82224, 32, 14)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sy_train_log2.shape\n",
    "\n",
    "naudio,nrow, ncol = Sy_train_log2.shape \n",
    "nchan_in = 1       # number of input channels. \n",
    "input_shape = (nrow,ncol,nchan_in)  # input shape of 1 image\n",
    "batch_shape = (naudio,nrow,ncol,nchan_in)  # shape of image batch\n",
    "\n",
    "Sy_train_log2 = Sy_train_log2.reshape(batch_shape)\n",
    "print(Sy_train_log2.shape)\n",
    "#this way convolution is done along time axis, each kernel looks at all frequencies at once\n",
    "S_input_shape = (Sy_train_log2.shape[1],Sy_train_log2.shape[2],nchan_in) #f,t,#channels\n",
    "\n",
    "S_input = keras.layers.Input(shape=S_input_shape)\n",
    "kernel_size = (8,)\n",
    "nchan_out = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 17:09:37.361343: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n",
      "2022-04-15 17:09:39.769103: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-04-15 17:09:39.769485: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-04-15 17:09:39.769514: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-04-15 17:09:39.769883: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-04-15 17:09:39.769960: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-04-15 17:09:41.577303: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 147345408 exceeds 10% of free system memory.\n",
      "2022-04-15 17:09:41.706960: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 147345408 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - 10s - loss: 0.2883 - mse: 0.2883 - val_loss: 0.6052 - val_mse: 0.6052 - 10s/epoch - 209ms/step\n",
      "   1/2570 [..............................] - ETA: 2:25 - loss: 0.6361 - mse: 0.6361"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 17:09:46.014422: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 147345408 exceeds 10% of free system memory.\n",
      "2022-04-15 17:09:46.148620: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 147345408 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2570/2570 [==============================] - 8s 3ms/step - loss: 0.6052 - mse: 0.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 17:09:54.704591: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 147345408 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - 4s - loss: 0.0823 - mse: 0.0823 - val_loss: 0.3800 - val_mse: 0.3800 - 4s/epoch - 85ms/step\n",
      "2570/2570 [==============================] - 8s 3ms/step - loss: 0.3800 - mse: 0.3800\n",
      "50/50 - 4s - loss: 0.0517 - mse: 0.0517 - val_loss: 0.6434 - val_mse: 0.6434 - 4s/epoch - 86ms/step\n",
      " 872/2570 [=========>....................] - ETA: 5s - loss: 0.6442 - mse: 0.6442"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m hist \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(Sy_temp,\n\u001b[1;32m     21\u001b[0m \t\t\ty_temp,\n\u001b[1;32m     22\u001b[0m \t\t\tepochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \t\t\tvalidation_data \u001b[38;5;241m=\u001b[39m (Sy_train_log2[:,\u001b[38;5;241m-\u001b[39mshape_time:,:],y_train_normalized),\n\u001b[1;32m     26\u001b[0m \t\t\tuse_multiprocessing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m validation_loss \u001b[38;5;241m=\u001b[39m hist\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 30\u001b[0m test_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSy_train_log2\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_normalized\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     31\u001b[0m val_loss\u001b[38;5;241m.\u001b[39mappend(validation_loss)\n\u001b[1;32m     32\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(hist\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/keras/engine/training.py:1716\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1715\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1716\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1717\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1718\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "best_validation_loss = np.inf\n",
    "zoom_factor = 1 #only look at part of the time data\n",
    "n = Sy_train.shape[0]\n",
    "shape_time = round(Sy_train.shape[1] * zoom_factor)\n",
    "steps_per_epoch = 50\n",
    "bs = 64\n",
    "m = bs*steps_per_epoch\n",
    "idx = np.arange(0,n,1)\n",
    "val_loss=[]\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "#save_log = os.path.join(trial_dir,pickle_name+\"_score.pkl\")\n",
    "#model_adjustable.summary()\n",
    "print('Start fitting the model...')\n",
    "for epoch in range(30):\n",
    "\tnp.random.shuffle(idx)\n",
    "\tSy_temp = Sy_train_log2[idx[:m],:shape_time,:]\n",
    "\ty_temp = y_train_normalized[idx[:m],:]\n",
    "\n",
    "\thist = model.fit(Sy_temp,\n",
    "\t\t\t\ty_temp,\n",
    "\t\t\t\tepochs=1,\n",
    "\t\t\t\tverbose=2,\n",
    "\t\t\t\tbatch_size=bs,\n",
    "\t\t\t\tvalidation_data = (Sy_train_log2[:,-shape_time:,:],y_train_normalized),\n",
    "\t\t\t\tuse_multiprocessing=False)\n",
    "\n",
    "\tvalidation_loss = hist.history['val_loss'][0]\n",
    "\n",
    "\ttest_loss.append(model.evaluate(Sy_train_log2,y_train_normalized)[0])\n",
    "\tval_loss.append(validation_loss)\n",
    "\ttrain_loss.append(hist.history['loss'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_sampler(df,params_normalized,idx,path_to_folder,J,Q,order):\n",
    "    \"\"\"\n",
    "    output a {input, ground truth} pair for the designated audio sample\n",
    "    \"\"\"\n",
    "    i=idx\n",
    "    y=params_normalized[i,:] #df.values[i,1:-1]\n",
    "    path_to_audio = os.path.join(path_to_folder,str(df.values[i,0])+\"_sound.wav\") \n",
    "    x,fs=librosa.load(path_to_audio)\n",
    "    Sy = getsc_new(x,J,Q,order)\n",
    "    while True:\n",
    "        #np.random.shuffle(idx)\n",
    "        #i=idx[0]\n",
    "        yield {'input': Sy,'y': y}\n",
    "\n",
    "        \n",
    "def data_generator(df, params_normalized, path_to_folder, J, Q, order, batch_size, idx, active_streamers,\n",
    "                        rate, random_state=12345678):\n",
    "    \"\"\"\n",
    "    use streamers to output a batch of {input groundtruth} pairs. \n",
    "    \"\"\"\n",
    "    seeds = []\n",
    "    for i in idx:\n",
    "        streamer = pescador.Streamer(feature_sampler, df, params_normalized, i,path_to_folder,J,Q,order)\n",
    "        seeds.append(streamer)\n",
    "\n",
    "    # Randomly shuffle the seeds\n",
    "    random.shuffle(seeds)\n",
    "\n",
    "    mux = pescador.StochasticMux(seeds, active_streamers, rate=rate, random_state=random_state)\n",
    "\n",
    "    return pescador.maps.buffer_stream(mux, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first run with small number of training\n",
    "epochs=12\n",
    "batch_size=32\n",
    "random_state=12345678\n",
    "active_streamers=1024\n",
    "path_to_train = \"/scratch/hh2263/drum_dataset/train/\"\n",
    "path_to_test = \"/scratch/hh2263/drum_dataset/test/\"\n",
    "J = 8\n",
    "Q = 1\n",
    "order = 1 # remember to go to order 2 eventually\n",
    "train_idx = df_train.values[0,:100]\n",
    "test_idx = df_test.values[0,:30]\n",
    "train_batches=data_generator(df,params_normalized, path_to_train,J, Q, order, batch_size, train_idx,active_streamers,rate=64,random_state=random_state)\n",
    "test_batches=data_generator(df,params_normalized, path_to_train,J, Q, order, batch_size, train_idx,active_streamers,rate=64,random_state=random_state)\n",
    "steps_per_epoch = len(train_idx) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = random.choice(os.listdir(path_to_train))\n",
    "rand_audio = os.path.join(path_to_train,fname)\n",
    "y = librosa.load(rand_audio)\n",
    "Sy = getsc_new(y,J,Q,order).T\n",
    "nrow, ncol = Sy.shape \n",
    "naudio = batch_size         # number of images in batch\n",
    "nchan_in = 1       # number of input channels.  1 since it is BW\n",
    "input_shape = (nrow,ncol,nchan_in)  # input shape of 1 image\n",
    "batch_shape = (naudio,nrow,ncol,nchan_in)  # shape of image batch\n",
    "x = S.reshape(batch_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preliminary test\n",
    "hist = model.fit_generator(\n",
    "        pescador.maps.keras_tuples(train_batches, 'input', 'y'),\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        validation_data=pescador.maps.keras_tuples(test_batches, 'input', 'y'),\n",
    "        validation_steps=1024,\n",
    "        verbose=1\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
