{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv1D, AveragePooling1D, Conv2D, MaxPooling2D,ReLU\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model #save and load models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "import IPython.display as ipd\n",
    "from kymatio import Scattering1D\n",
    "import hitdifferentparts\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pescador\n",
    "import random\n",
    "import os\n",
    "import librosa\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scattering_J-06_Q-01_order2.pkl',\n",
       " 'scattering_J-10_Q-01_order1.pkl',\n",
       " 'scattering_J-12_Q-01_order1.pkl',\n",
       " 'scattering_J-14_Q-01_order1.pkl',\n",
       " 'scattering_J-06_Q-01_order1.pkl',\n",
       " 'scattering_J-08_Q-01_order1.pkl',\n",
       " 'scattering_J-10_Q-01_order2.pkl',\n",
       " 'scattering_J-08_Q-01_order2.pkl',\n",
       " 'scattering_J-12_Q-01_order2.pkl',\n",
       " 'scattering_J-14_Q-01_order2.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_dir = \"/scratch/hh2263/drum_data/pkl_data/\"\n",
    "os.listdir(pkl_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 12 14:51:29 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.39       Driver Version: 418.39       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P40           On   | 00000000:04:00.0 Off |                    0 |\r\n",
      "| N/A   16C    P8     9W / 250W |     10MiB / 22919MiB |      0%   E. Process |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla P40           On   | 00000000:05:00.0 Off |                    0 |\r\n",
      "| N/A   13C    P8     9W / 250W |     10MiB / 22919MiB |      0%   E. Process |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open J-8,Q=1,O=2 pkl file\n",
    "J = 8\n",
    "Q = 1\n",
    "order = 2\n",
    "pkl_path = '/scratch/hh2263/drum_data/pkl_data/scattering_J-08_Q-01_order2.pkl'\n",
    "pkl_file = open(pkl_path, 'rb')\n",
    "Sy_train,y_train = pickle.load(pkl_file) \n",
    "\n",
    "pkl_path_val = '/scratch/hh2263/drum_data/val/J_8_Q_1_order_2.pkl'\n",
    "pkl_val = open(pkl_path_val,'rb')\n",
    "Sy_val,y_val = pickle.load(pkl_val)\n",
    "Sy_val = Sy_val.reshape((Sy_val.shape[2],Sy_val.shape[0],Sy_val.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82224, 128, 43) (7776, 128, 43) (82224, 5) (7776, 5) 128 43\n"
     ]
    }
   ],
   "source": [
    "input_x = Sy_train.shape[1]\n",
    "input_y = Sy_train.shape[2]\n",
    "print(Sy_train.shape,Sy_val.shape,y_train.shape,y_val.shape,input_x,input_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 12 14:51:34 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.39       Driver Version: 418.39       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P40           On   | 00000000:04:00.0 Off |                    0 |\r\n",
      "| N/A   15C    P8     9W / 250W |     10MiB / 22919MiB |      0%   E. Process |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla P40           On   | 00000000:05:00.0 Off |                    0 |\r\n",
      "| N/A   13C    P8     9W / 250W |     10MiB / 22919MiB |      0%   E. Process |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./train_param.csv\")\n",
    "df_test = pd.read_csv(\"./test_param.csv\")\n",
    "df_val = pd.read_csv(\"./val_param.csv\")\n",
    "df_full = pd.read_csv(\"./diffshapes_param.csv\")\n",
    "\n",
    "# normalization of the physical parameters\n",
    "params = df_train.values[:,1:-1]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(params)\n",
    "\n",
    "#normalize training and validation set\n",
    "y_train_normalized = scaler.transform(y_train)\n",
    "y_val_normalized = scaler.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the model\n",
    "def create_model(J,Q,order,input_x,input_y,k_size,layer_size,nchan_out):\n",
    "    #fname = random.choice(os.listdir(path_to_train))\n",
    "    #rand_audio = os.path.join(path_to_train,fname)\n",
    "    #y,sr = librosa.load(rand_audio)\n",
    "    #N = len(y)\n",
    "    #scattering = Scattering1D(J = J,shape=(N,), Q = Q, max_order=order)\n",
    "    \n",
    "    #Sy = getsc_new(torch.Tensor(y),J,Q,order,scattering).T\n",
    "    #nrow, ncol = Sy.shape \n",
    "    nrow = input_x\n",
    "    ncol = input_y\n",
    "    #naudio = batch_size         # number of images in batch\n",
    "    nchan_in = 1       # number of input channels.  1 since it is BW\n",
    "    #input_shape = (nrow,ncol,nchan_in)  # input shape of 1 image\n",
    "    input_shape = (input_x,input_y)#Sy.shape\n",
    "    #batch_shape = (naudio,nrow,ncol,nchan_in)  # shape of image batch\n",
    "    #x = Sy.reshape(batch_shape)\n",
    "    kernel_size = (k_size,)\n",
    "    #nchan_out = 16\n",
    "\n",
    "    K.clear_session()\n",
    "    model=Sequential()\n",
    "    #1 conv layer +  1 batch normalization + nonlinear activation + pooling\n",
    "    model.add(Conv1D(input_shape=input_shape, filters=nchan_out,\n",
    "                     kernel_size=kernel_size, padding=\"same\",name='conv1'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(AveragePooling1D(pool_size=(4,)))\n",
    "    \n",
    "   #second time\n",
    "    model.add(Conv1D(filters=nchan_out,\n",
    "                     kernel_size=kernel_size, padding=\"same\",name='conv2' ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(AveragePooling1D(pool_size=(4,)))\n",
    "    \n",
    "    #third time\n",
    "    if layer_size>=3:\n",
    "        model.add(Conv1D(filters=nchan_out,\n",
    "                         kernel_size=kernel_size, padding=\"same\",name='conv3' ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(AveragePooling1D(pool_size=(4,)))\n",
    "        if layer_size==4:\n",
    "        #fourth time\n",
    "            model.add(Conv1D(filters=nchan_out,\n",
    "                             kernel_size=kernel_size, padding=\"same\",name='conv4' ))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(AveragePooling1D(pool_size=(2,)))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    #what activation should be chosen for last layer, for regression problem? should be a linear function\n",
    "    model.add(Dense(5, activation='linear')) #output layer that corresponds to the 5 physical parameters.\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hh2263/miniconda3/envs/drum-1.15/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv1D)               (None, 128, 16)           5520      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 16)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv1D)               (None, 32, 16)            2064      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv1D)               (None, 8, 16)             2064      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 16)             64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv1D)               (None, 2, 16)             2064      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 16)             64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 16)             64        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 13,701\n",
      "Trainable params: 13,413\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_model(J,Q,order,input_x,input_y,k_size=8,layer_size=4,nchan_out=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 12 14:51:35 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.39       Driver Version: 418.39       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P40           On   | 00000000:04:00.0 Off |                    0 |\r\n",
      "| N/A   15C    P8    13W / 250W |     10MiB / 22919MiB |      0%   E. Process |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla P40           On   | 00000000:05:00.0 Off |                    0 |\r\n",
      "| N/A   13C    P8     9W / 250W |     10MiB / 22919MiB |      0%   E. Process |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training everything at once and validate - apparently overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82224 samples, validate on 7776 samples\n",
      "82224/82224 [==============================] - 21s 250us/sample - loss: 0.0448 - mean_squared_error: 0.0448 - val_loss: 11544.8017 - val_mean_squared_error: 11544.7998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b05fdf91550>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Sy_train,\n",
    "          y_train_normalized,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          validation_data = (Sy_val,y_val_normalized),\n",
    "         use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce model complexity to 3 layers - worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv1D)               (None, 128, 16)           5520      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 16)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv1D)               (None, 32, 16)            2064      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv1D)               (None, 8, 16)             2064      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 16)             64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 16)             64        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 12,597\n",
      "Trainable params: 12,341\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = create_model(J,Q,order,input_x,input_y,k_size=8,layer_size=3,nchan_out=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82224 samples, validate on 7776 samples\n",
      "82224/82224 [==============================] - 16s 191us/sample - loss: 0.0437 - mean_squared_error: 0.0437 - val_loss: 465487.7260 - val_mean_squared_error: 465487.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b06d3fc30d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(Sy_train,\n",
    "          y_train_normalized,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          validation_data = (Sy_val,y_val_normalized),\n",
    "         use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## increase kernel size helped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv1D)               (None, 128, 16)           11024     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 16)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv1D)               (None, 32, 16)            4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv1D)               (None, 8, 16)             4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 16)             64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv1D)               (None, 2, 16)             4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 16)             64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 16)             64        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 25,349\n",
      "Trainable params: 25,061\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3 = create_model(J,Q,order,input_x,input_y,k_size=16,layer_size=4,nchan_out=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82224 samples, validate on 7776 samples\n",
      "82224/82224 [==============================] - 19s 225us/sample - loss: 0.0459 - mean_squared_error: 0.0459 - val_loss: 5457.1812 - val_mean_squared_error: 5457.1816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b0c8b750c10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(Sy_train,\n",
    "          y_train_normalized,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          validation_data = (Sy_val,y_val_normalized),\n",
    "         use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv1D)               (None, 128, 16)           11024     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 16)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv1D)               (None, 32, 16)            4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv1D)               (None, 8, 16)             4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 16)             64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 16)             64        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 22,197\n",
      "Trainable params: 21,941\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model4 = create_model(J,Q,order,input_x,input_y,k_size=16,layer_size=3,nchan_out=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../output/train_pkl\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "model_filepath = os.path.join(output_dir, \"cp.ckpt\")\n",
    "log_filepath = os.path.join(output_dir, 'train_log.csv')\n",
    "\n",
    "callbacks = []\n",
    "callbacks.append(EarlyStopping(monitor='val_loss',patience=0,verbose=1))\n",
    "callbacks.append(ModelCheckpoint(model_filepath, save_best_only=True))\n",
    "callbacks.append(CSVLogger(log_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82224 samples, validate on 7776 samples\n",
      "82224/82224 [==============================] - 3s 38us/sample - loss: 0.2229 - mean_squared_error: 0.2229 - val_loss: 0.0458 - val_mean_squared_error: 0.0458\n",
      "Train on 82224 samples, validate on 7776 samples\n",
      "82224/82224 [==============================] - 2s 21us/sample - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.2898 - val_mean_squared_error: 0.2898\n",
      "Train on 82224 samples, validate on 7776 samples\n",
      "82224/82224 [==============================] - 2s 21us/sample - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 1.3946 - val_mean_squared_error: 1.3946\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    model4.fit(Sy_train,\n",
    "              y_train_normalized,\n",
    "              epochs=1,\n",
    "              verbose=1,\n",
    "              batch_size=1024,\n",
    "              shuffle=True,\n",
    "              callbacks = callbacks,\n",
    "              validation_data = (Sy_val,y_val_normalized),\n",
    "             use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try with datagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_sampler(Sy_all,y_all,idx):\n",
    "    \"\"\"\n",
    "    output a {input, ground truth} pair for the designated audio sample\n",
    "    \"\"\"\n",
    "    i=idx\n",
    "    Sy = Sy_all[i,:,:]\n",
    "    y = y_all[i,:]\n",
    "    while True:\n",
    "        yield {'input': Sy,'y': y}\n",
    "\n",
    "        \n",
    "def data_generator(Sy_all,y_all, batch_size, idx, active_streamers,rate,mode,random_state):\n",
    "    \"\"\"\n",
    "    use streamers to output a batch of {input groundtruth} pairs. \n",
    "    \"\"\"\n",
    "\n",
    "    seeds = []\n",
    "    for i in idx:\n",
    "        streamer = pescador.Streamer(feature_sampler,Sy_all,y_all,i)\n",
    "        seeds.append(streamer)\n",
    "\n",
    "    # Randomly shuffle the seeds\n",
    "    random.shuffle(seeds)\n",
    "\n",
    "    mux = pescador.StochasticMux(seeds, active_streamers, rate=rate, random_state=random_state,mode=mode)\n",
    "   \n",
    "    if batch_size == 1:\n",
    "        return mux\n",
    "    else:\n",
    "        return pescador.maps.buffer_stream(mux, batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=12\n",
    "batch_size=32\n",
    "random_state=12345678\n",
    "active_streamers=32\n",
    "mode='with_replacement'\n",
    "rate=1\n",
    "train_idx = np.arange(0,Sy_train.shape[0],1)\n",
    "train_batches=data_generator(Sy_train,y_train_normalized,batch_size, train_idx,active_streamers,rate=rate,mode=mode,random_state=random_state)\n",
    "steps_per_epoch = len(train_idx) // batch_size\n",
    "\n",
    "train_gen = pescador.maps.keras_tuples(train_batches, 'input', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv1D)               (None, 128, 16)           11024     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 16)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv1D)               (None, 32, 16)            4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv1D)               (None, 8, 16)             4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 16)             64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv1D)               (None, 2, 16)             4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 16)             64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 16)             64        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 25,349\n",
      "Trainable params: 25,061\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model5 = create_model(J,Q,order,input_x,input_y,k_size=16,layer_size=4,nchan_out=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 12 14:51:44 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.39       Driver Version: 418.39       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P40           On   | 00000000:04:00.0 Off |                    0 |\r\n",
      "| N/A   15C    P8     9W / 250W |     10MiB / 22919MiB |      0%   E. Process |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla P40           On   | 00000000:05:00.0 Off |                    0 |\r\n",
      "| N/A   13C    P8     9W / 250W |     10MiB / 22919MiB |      0%   E. Process |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model5.fit(pescador.maps.keras_tuples(train_batches, 'input', 'y'),\n",
    "              steps_per_epoch=1,\n",
    "              epochs=1,\n",
    "              use_multiprocessing=False,\n",
    "              verbose=1,\n",
    "              callbacks = callbacks,\n",
    "              #validation_data = (Sy_val,y_val_normalized)\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-594052644961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     model5.fit(train_gen,\n\u001b[1;32m      3\u001b[0m               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model5.fit(pescador.maps.keras_tuples(train_batches, 'input', 'y'),\n",
    "              steps_per_epoch=1,\n",
    "              epochs=1,\n",
    "              use_multiprocessing=True,\n",
    "              verbose=1,\n",
    "              callbacks = callbacks,\n",
    "              validation_data = (Sy_val,y_val_normalized)\n",
    "             )\n",
    "    #print('done fitting')\n",
    "   # loss,mse = model.evaluate(Sy_val,y_val_normalized)\n",
    "   # print(loss,mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82224, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_idx = np.arange(0,params.shape[0],1)#np.arange(0,1000,1) #df_train.values[:1000,0]\n",
    "test_idx = np.arange(0,df_test.values.shape[0],1) #df_test.values[:300,0]\n",
    "val_idx = np.arange(0,df_val.values.shape[0],1)\n",
    "\n",
    "\n",
    "test_params_normalized = scaler.transform(df_test.values[:,1:-1])\n",
    "val_params_normalized = scaler.transform(df_val.values[:,1:-1])\n",
    "train_batches=data_generator(df_train,train_params_normalized, path_to_train,J, Q, order, batch_size, train_idx,active_streamers,rate=rate,mode=mode,random_state=random_state)\n",
    "test_batches=data_generator(df_test,test_params_normalized, path_to_test,J, Q, order, batch_size, test_idx,active_streamers,rate=rate,mode=mode,random_state=random_state)\n",
    "val_batches = data_generator(df_val,val_params_normalized, path_to_val,J, Q, order, batch_size, val_idx,active_streamers,rate=64,mode=mode,random_state=random_state)\n",
    "steps_per_epoch = len(train_idx) // batch_size\n",
    "\n",
    "train_gen = pescador.maps.keras_tuples(train_batches, 'input', 'y')\n",
    "test_gen = pescador.maps.keras_tuples(test_batches, 'input', 'y')\n",
    "val_gen = pescador.maps.keras_tuples(val_batches, 'input', 'y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
