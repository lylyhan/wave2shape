{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv1D, AveragePooling1D, Conv2D, MaxPooling2D,ReLU\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model #save and load models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "import IPython.display as ipd\n",
    "from kymatio import Scattering1D\n",
    "import hitdifferentparts\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pescador\n",
    "import random\n",
    "import os\n",
    "import librosa\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scattering_J-06_Q-01_order2.pkl',\n",
       " 'scattering_J-10_Q-01_order1.pkl',\n",
       " 'scattering_J-12_Q-01_order1.pkl',\n",
       " 'scattering_J-14_Q-01_order1.pkl',\n",
       " 'scattering_J-06_Q-01_order1.pkl',\n",
       " 'scattering_J-08_Q-01_order1.pkl',\n",
       " 'scattering_J-10_Q-01_order2.pkl',\n",
       " 'scattering_J-08_Q-01_order2.pkl',\n",
       " 'scattering_J-12_Q-01_order2.pkl',\n",
       " 'scattering_J-14_Q-01_order2.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_dir = \"/scratch/hh2263/drum_data/pkl_data/\"\n",
    "os.listdir(pkl_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open J-8,Q=1,O=2 pkl file\n",
    "J = 8\n",
    "Q = 1\n",
    "order = 2\n",
    "pkl_path = '/scratch/hh2263/drum_data/pkl_data/scattering_J-08_Q-01_order2.pkl'\n",
    "pkl_file = open(pkl_path, 'rb')\n",
    "Sy_train,y_train = pickle.load(pkl_file) \n",
    "\n",
    "pkl_path_val = '/scratch/hh2263/drum_data/val/J_8_Q_1_order_2.pkl'\n",
    "pkl_val = open(pkl_path_val,'rb')\n",
    "Sy_val,y_val = pickle.load(pkl_val)\n",
    "Sy_val = Sy_val.reshape((Sy_val.shape[2],Sy_val.shape[0],Sy_val.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82224, 128, 43) (7776, 128, 43) (82224, 5) (7776, 5) 128 43\n"
     ]
    }
   ],
   "source": [
    "input_x = Sy_train.shape[1]\n",
    "input_y = Sy_train.shape[2]\n",
    "print(Sy_train.shape,Sy_val.shape,y_train.shape,y_val.shape,input_x,input_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./train_param.csv\")\n",
    "df_test = pd.read_csv(\"./test_param.csv\")\n",
    "df_val = pd.read_csv(\"./val_param.csv\")\n",
    "df_full = pd.read_csv(\"./diffshapes_param.csv\")\n",
    "\n",
    "# normalization of the physical parameters\n",
    "params = df_train.values[:,1:-1]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(params)\n",
    "\n",
    "#normalize training and validation set\n",
    "y_train_normalized = scaler.transform(y_train)\n",
    "y_val_normalized = scaler.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the model\n",
    "def create_model(J,Q,order,input_x,input_y,k_size,layer_size,nchan_out):\n",
    "    #fname = random.choice(os.listdir(path_to_train))\n",
    "    #rand_audio = os.path.join(path_to_train,fname)\n",
    "    #y,sr = librosa.load(rand_audio)\n",
    "    #N = len(y)\n",
    "    #scattering = Scattering1D(J = J,shape=(N,), Q = Q, max_order=order)\n",
    "    \n",
    "    #Sy = getsc_new(torch.Tensor(y),J,Q,order,scattering).T\n",
    "    #nrow, ncol = Sy.shape \n",
    "    nrow = input_x\n",
    "    ncol = input_y\n",
    "    #naudio = batch_size         # number of images in batch\n",
    "    nchan_in = 1       # number of input channels.  1 since it is BW\n",
    "    #input_shape = (nrow,ncol,nchan_in)  # input shape of 1 image\n",
    "    input_shape = (input_x,input_y)#Sy.shape\n",
    "    #batch_shape = (naudio,nrow,ncol,nchan_in)  # shape of image batch\n",
    "    #x = Sy.reshape(batch_shape)\n",
    "    kernel_size = (k_size,)\n",
    "    #nchan_out = 16\n",
    "\n",
    "    K.clear_session()\n",
    "    model=Sequential()\n",
    "    #1 conv layer +  1 batch normalization + nonlinear activation + pooling\n",
    "    model.add(Conv1D(input_shape=input_shape, filters=nchan_out,\n",
    "                     kernel_size=kernel_size, padding=\"same\",name='conv1'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(AveragePooling1D(pool_size=(4,)))\n",
    "    \n",
    "   #second time\n",
    "    model.add(Conv1D(filters=nchan_out,\n",
    "                     kernel_size=kernel_size, padding=\"same\",name='conv2' ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(AveragePooling1D(pool_size=(4,)))\n",
    "    \n",
    "    #third time\n",
    "    if layer_size>=3:\n",
    "        model.add(Conv1D(filters=nchan_out,\n",
    "                         kernel_size=kernel_size, padding=\"same\",name='conv3' ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(AveragePooling1D(pool_size=(4,)))\n",
    "        if layer_size==4:\n",
    "        #fourth time\n",
    "            model.add(Conv1D(filters=nchan_out,\n",
    "                             kernel_size=kernel_size, padding=\"same\",name='conv4' ))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(AveragePooling1D(pool_size=(2,)))\n",
    "            if layer_size ==5:\n",
    "                model.add(Conv1D(filters=nchan_out,\n",
    "                             kernel_size=kernel_size, padding=\"same\",name='conv5' ))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(AveragePooling1D(pool_size=(2,)))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    #what activation should be chosen for last layer, for regression problem? should be a linear function\n",
    "    model.add(Dense(5, activation='linear')) #output layer that corresponds to the 5 physical parameters.\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "    \n",
    "    #print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv1D)               (None, 128, 8)            1384      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 8)            32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 8)            0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 32, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv1D)               (None, 32, 8)             264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 8)             32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 8)             0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 8, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv1D)               (None, 8, 8)              264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8)              32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 8)              0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 2, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv1D)               (None, 2, 8)              264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 8)              32        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 8)              0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 1, 8)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 8)              32        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 3,493\n",
      "Trainable params: 3,285\n",
      "Non-trainable params: 208\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=create_model(J,Q,order,input_x,input_y,k_size=4,layer_size=4,nchan_out=8)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82224, 128, 43)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sy_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82224 samples, validate on 7776 samples\n",
      "Epoch 1/8\n",
      "82224/82224 - 12s - loss: 0.7081 - mean_squared_error: 0.7081 - val_loss: 0.1077 - val_mean_squared_error: 0.1077\n",
      "Epoch 2/8\n",
      "82224/82224 - 4s - loss: 0.1971 - mean_squared_error: 0.1971 - val_loss: 0.0677 - val_mean_squared_error: 0.0677\n",
      "Epoch 3/8\n",
      "82224/82224 - 4s - loss: 0.1117 - mean_squared_error: 0.1117 - val_loss: 0.0443 - val_mean_squared_error: 0.0443\n",
      "Epoch 4/8\n",
      "82224/82224 - 4s - loss: 0.0768 - mean_squared_error: 0.0768 - val_loss: 0.0342 - val_mean_squared_error: 0.0342\n",
      "Epoch 5/8\n",
      "82224/82224 - 4s - loss: 0.0593 - mean_squared_error: 0.0593 - val_loss: 0.0350 - val_mean_squared_error: 0.0350\n",
      "Epoch 6/8\n",
      "82224/82224 - 4s - loss: 0.0511 - mean_squared_error: 0.0511 - val_loss: 0.0427 - val_mean_squared_error: 0.0427\n",
      "Epoch 7/8\n",
      "82224/82224 - 4s - loss: 0.0472 - mean_squared_error: 0.0472 - val_loss: 0.0537 - val_mean_squared_error: 0.0537\n",
      "Epoch 8/8\n",
      "82224/82224 - 4s - loss: 0.0450 - mean_squared_error: 0.0450 - val_loss: 0.0664 - val_mean_squared_error: 0.0664\n"
     ]
    }
   ],
   "source": [
    "#feed the entire thing, use batch size of 4096\n",
    "model=create_model(J,Q,order,input_x,input_y,k_size=4,layer_size=4,nchan_out=8)\n",
    "hist = model.fit(Sy_train,\n",
    "              y_train_normalized,\n",
    "              epochs=8,\n",
    "              verbose=2,\n",
    "              batch_size=4096,\n",
    "              validation_data = (Sy_val,y_val_normalized),\n",
    "             use_multiprocessing=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82224 samples, validate on 7776 samples\n",
      "Epoch 1/8\n",
      "82224/82224 - 27s - loss: 0.0558 - mean_squared_error: 0.0558 - val_loss: 901.6907 - val_mean_squared_error: 901.6904\n",
      "Epoch 2/8\n",
      "82224/82224 - 26s - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 3733.2078 - val_mean_squared_error: 3733.2080\n",
      "Epoch 3/8\n",
      "82224/82224 - 25s - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 12082.9765 - val_mean_squared_error: 12082.9785\n",
      "Epoch 4/8\n",
      "82224/82224 - 25s - loss: 0.0300 - mean_squared_error: 0.0300 - val_loss: 30886.8858 - val_mean_squared_error: 30886.8945\n",
      "Epoch 5/8\n",
      "82224/82224 - 25s - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 34040.8927 - val_mean_squared_error: 34040.8984\n",
      "Epoch 6/8\n",
      "82224/82224 - 26s - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 16500.4232 - val_mean_squared_error: 16500.4219\n",
      "Epoch 7/8\n",
      "82224/82224 - 26s - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 16218.1727 - val_mean_squared_error: 16218.1738\n",
      "Epoch 8/8\n",
      "82224/82224 - 26s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 20951.7296 - val_mean_squared_error: 20951.7363\n"
     ]
    }
   ],
   "source": [
    "#feed the entire thing, use batch size of 64\n",
    "model=create_model(J,Q,order,input_x,input_y,k_size=4,layer_size=4,nchan_out=8)\n",
    "hist = model.fit(Sy_train,\n",
    "              y_train_normalized,\n",
    "              epochs=8,\n",
    "              verbose=2,\n",
    "              batch_size=64,\n",
    "              validation_data = (Sy_val,y_val_normalized),\n",
    "             use_multiprocessing=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(0,10,1)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10278 samples, validate on 7776 samples\n",
      "10278/10278 [==============================] - 5s 515us/sample - loss: 0.1939 - mean_squared_error: 0.1939 - val_loss: 0.0433 - val_mean_squared_error: 0.0433\n",
      "Train on 10278 samples, validate on 7776 samples\n",
      "10278/10278 [==============================] - 4s 390us/sample - loss: 0.0508 - mean_squared_error: 0.0508 - val_loss: 0.2056 - val_mean_squared_error: 0.2056\n",
      "Train on 10278 samples, validate on 7776 samples\n",
      "10278/10278 [==============================] - 4s 389us/sample - loss: 0.0467 - mean_squared_error: 0.0467 - val_loss: 4.5236 - val_mean_squared_error: 4.5236\n",
      "Train on 10278 samples, validate on 7776 samples\n",
      "10278/10278 [==============================] - 4s 392us/sample - loss: 0.0440 - mean_squared_error: 0.0440 - val_loss: 30.0759 - val_mean_squared_error: 30.0759\n",
      "Train on 10278 samples, validate on 7776 samples\n",
      "10278/10278 [==============================] - 4s 388us/sample - loss: 0.0422 - mean_squared_error: 0.0422 - val_loss: 93.4803 - val_mean_squared_error: 93.4803\n",
      "Train on 10278 samples, validate on 7776 samples\n",
      "10278/10278 [==============================] - 4s 388us/sample - loss: 0.0406 - mean_squared_error: 0.0406 - val_loss: 117.2675 - val_mean_squared_error: 117.2675\n",
      "Train on 10278 samples, validate on 7776 samples\n",
      "10278/10278 [==============================] - 4s 389us/sample - loss: 0.0396 - mean_squared_error: 0.0396 - val_loss: 167.5093 - val_mean_squared_error: 167.5093\n",
      "Train on 10278 samples, validate on 7776 samples\n",
      "10278/10278 [==============================] - 4s 388us/sample - loss: 0.0392 - mean_squared_error: 0.0392 - val_loss: 228.7889 - val_mean_squared_error: 228.7889\n"
     ]
    }
   ],
   "source": [
    "#divide the training up to 1/8, use batch size of 64\n",
    "n = Sy_train.shape[0]\n",
    "m = n // 8\n",
    "idx = np.arange(0,n,1)\n",
    "model=create_model(J,Q,order,input_x,input_y,k_size=4,layer_size=4,nchan_out=8)\n",
    "for epoch in range(8):\n",
    "    np.random.shuffle(idx)\n",
    "    Sy_temp = Sy_train[idx[:m],:,:]\n",
    "    y_temp = y_train_normalized[idx[:m],:]\n",
    "    model.fit(Sy_temp,\n",
    "                y_temp,\n",
    "                epochs=1,\n",
    "                verbose=1,\n",
    "                batch_size=64,\n",
    "                validation_data = (Sy_val,y_val_normalized),\n",
    "                use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5139 samples, validate on 7776 samples\n",
      "5139/5139 [==============================] - 4s 709us/sample - loss: 0.2821 - mean_squared_error: 0.2821 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
      "Train on 5139 samples, validate on 7776 samples\n",
      "5139/5139 [==============================] - 2s 461us/sample - loss: 0.0548 - mean_squared_error: 0.0548 - val_loss: 0.0517 - val_mean_squared_error: 0.0517\n",
      "Train on 5139 samples, validate on 7776 samples\n",
      "5139/5139 [==============================] - 2s 460us/sample - loss: 0.0454 - mean_squared_error: 0.0454 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Train on 5139 samples, validate on 7776 samples\n",
      "5139/5139 [==============================] - 2s 467us/sample - loss: 0.0432 - mean_squared_error: 0.0432 - val_loss: 0.1593 - val_mean_squared_error: 0.1593\n",
      "Train on 5139 samples, validate on 7776 samples\n",
      "5139/5139 [==============================] - 2s 462us/sample - loss: 0.0431 - mean_squared_error: 0.0431 - val_loss: 0.2941 - val_mean_squared_error: 0.2941\n",
      "Train on 5139 samples, validate on 7776 samples\n",
      "5139/5139 [==============================] - 2s 459us/sample - loss: 0.0419 - mean_squared_error: 0.0419 - val_loss: 0.8037 - val_mean_squared_error: 0.8037\n",
      "Train on 5139 samples, validate on 7776 samples\n",
      "5139/5139 [==============================] - 2s 461us/sample - loss: 0.0406 - mean_squared_error: 0.0406 - val_loss: 1.9100 - val_mean_squared_error: 1.9100\n",
      "Train on 5139 samples, validate on 7776 samples\n",
      "5139/5139 [==============================] - 2s 461us/sample - loss: 0.0402 - mean_squared_error: 0.0402 - val_loss: 4.3875 - val_mean_squared_error: 4.3875\n"
     ]
    }
   ],
   "source": [
    "#divide the training up to 1/16, use batch size of 64\n",
    "n = Sy_train.shape[0]\n",
    "m = n // 16\n",
    "idx = np.arange(0,n,1)\n",
    "model=create_model(J,Q,order,input_x,input_y,k_size=4,layer_size=4,nchan_out=8)\n",
    "for epoch in range(8):\n",
    "    np.random.shuffle(idx)\n",
    "    Sy_temp = Sy_train[idx[:m],:,:]\n",
    "    y_temp = y_train_normalized[idx[:m],:]\n",
    "    model.fit(Sy_temp,\n",
    "                y_temp,\n",
    "                epochs=1,\n",
    "                verbose=1,\n",
    "                batch_size=64,\n",
    "                validation_data = (Sy_val,y_val_normalized),\n",
    "                use_multiprocessing=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82224 samples, validate on 7776 samples\n",
      "Epoch 1/2\n",
      "82224/82224 [==============================] - 5s 63us/sample - loss: 0.9586 - mean_squared_error: 0.9586 - val_loss: 0.1305 - val_mean_squared_error: 0.1305\n",
      "Epoch 2/2\n",
      "82224/82224 [==============================] - 4s 49us/sample - loss: 0.3045 - mean_squared_error: 0.3045 - val_loss: 0.0982 - val_mean_squared_error: 0.0982\n",
      "4096\n",
      "Train on 82224 samples, validate on 7776 samples\n",
      "Epoch 1/2\n",
      "82224/82224 [==============================] - 4s 52us/sample - loss: 0.1584 - mean_squared_error: 0.1584 - val_loss: 0.0609 - val_mean_squared_error: 0.0609\n",
      "Epoch 2/2\n",
      "82224/82224 [==============================] - 4s 52us/sample - loss: 0.0920 - mean_squared_error: 0.0920 - val_loss: 0.0394 - val_mean_squared_error: 0.0394\n",
      "2048\n",
      "Train on 82224 samples, validate on 7776 samples\n",
      "Epoch 1/2\n",
      "82224/82224 [==============================] - 5s 60us/sample - loss: 0.0610 - mean_squared_error: 0.0610 - val_loss: 0.0264 - val_mean_squared_error: 0.0264\n",
      "Epoch 2/2\n",
      "82224/82224 [==============================] - 5s 55us/sample - loss: 0.0499 - mean_squared_error: 0.0499 - val_loss: 0.0367 - val_mean_squared_error: 0.0367\n",
      "1024\n",
      "Train on 82224 samples, validate on 7776 samples\n",
      "Epoch 1/2\n",
      "82224/82224 [==============================] - 4s 51us/sample - loss: 0.0465 - mean_squared_error: 0.0465 - val_loss: 0.4634 - val_mean_squared_error: 0.4634\n",
      "Epoch 2/2\n",
      "82224/82224 [==============================] - 4s 47us/sample - loss: 0.0438 - mean_squared_error: 0.0438 - val_loss: 5.4290 - val_mean_squared_error: 5.4290\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "#feed the entire thing, start with big batch size 8192 for three epoch, then decrease batch size\n",
    "\n",
    "model=create_model(J,Q,order,input_x,input_y,k_size=4,layer_size=4,nchan_out=8)\n",
    "bs = 8192\n",
    "for epoch in range(4):\n",
    "    model.fit(Sy_train,\n",
    "              y_train_normalized,\n",
    "              epochs=2,\n",
    "              verbose=1,\n",
    "              batch_size=bs,\n",
    "              validation_data = (Sy_val,y_val_normalized),\n",
    "             use_multiprocessing=True)\n",
    "    \n",
    "    bs=bs//2\n",
    "    print(bs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82224 samples, validate on 7776 samples\n",
      "Epoch 1/2\n",
      "82224/82224 [==============================] - 5s 64us/sample - loss: 0.6895 - mean_squared_error: 0.6895 - val_loss: 0.1145 - val_mean_squared_error: 0.1145\n",
      "Epoch 2/2\n",
      "82224/82224 [==============================] - 4s 50us/sample - loss: 0.1814 - mean_squared_error: 0.1814 - val_loss: 0.0799 - val_mean_squared_error: 0.0799\n",
      "2048\n",
      "Train on 82224 samples, validate on 7776 samples\n",
      "Epoch 1/2\n",
      "82224/82224 [==============================] - 4s 53us/sample - loss: 0.0870 - mean_squared_error: 0.0870 - val_loss: 0.0398 - val_mean_squared_error: 0.0398\n",
      "Epoch 2/2\n",
      "82224/82224 [==============================] - 5s 55us/sample - loss: 0.0524 - mean_squared_error: 0.0524 - val_loss: 0.0303 - val_mean_squared_error: 0.0303\n",
      "1024\n",
      "Train on 82224 samples, validate on 7776 samples\n",
      "Epoch 1/2\n",
      "82224/82224 [==============================] - 4s 46us/sample - loss: 0.0447 - mean_squared_error: 0.0447 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
      "Epoch 2/2\n",
      "82224/82224 [==============================] - 4s 46us/sample - loss: 0.0417 - mean_squared_error: 0.0417 - val_loss: 0.0391 - val_mean_squared_error: 0.0391\n",
      "512\n",
      "Train on 82224 samples, validate on 7776 samples\n",
      "Epoch 1/2\n",
      "82224/82224 [==============================] - 6s 68us/sample - loss: 0.0408 - mean_squared_error: 0.0408 - val_loss: 0.0821 - val_mean_squared_error: 0.0821\n",
      "Epoch 2/2\n",
      "82224/82224 [==============================] - 5s 63us/sample - loss: 0.0389 - mean_squared_error: 0.0389 - val_loss: 25.4934 - val_mean_squared_error: 25.4934\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "#feed the entire thing, start with big batch size 4096 for three epoch, then decrease batch size\n",
    "\n",
    "model=create_model(J,Q,order,input_x,input_y,k_size=4,layer_size=4,nchan_out=8)\n",
    "bs = 4096\n",
    "for epoch in range(4):\n",
    "    model.fit(Sy_train,\n",
    "              y_train_normalized,\n",
    "              epochs=2,\n",
    "              verbose=1,\n",
    "              batch_size=bs,\n",
    "              validation_data = (Sy_val,y_val_normalized),\n",
    "             use_multiprocessing=True)\n",
    "    \n",
    "    bs=bs//2\n",
    "    print(bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82224 samples, validate on 7776 samples\n",
      "Epoch 1/4\n",
      "82224/82224 [==============================] - 5s 63us/sample - loss: 0.6700 - mean_squared_error: 0.6700 - val_loss: 0.0915 - val_mean_squared_error: 0.0915\n",
      "Epoch 2/4\n",
      "82224/82224 [==============================] - 4s 52us/sample - loss: 0.1786 - mean_squared_error: 0.1786 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
      "Epoch 3/4\n",
      "82224/82224 [==============================] - 4s 52us/sample - loss: 0.1019 - mean_squared_error: 0.1019 - val_loss: 0.0294 - val_mean_squared_error: 0.0294\n",
      "Epoch 4/4\n",
      "82224/82224 [==============================] - 4s 52us/sample - loss: 0.0697 - mean_squared_error: 0.0697 - val_loss: 0.0292 - val_mean_squared_error: 0.0292\n",
      "2048\n",
      "Train on 82224 samples, validate on 7776 samples\n",
      "Epoch 1/4\n",
      "82224/82224 [==============================] - 5s 56us/sample - loss: 0.0537 - mean_squared_error: 0.0537 - val_loss: 0.0510 - val_mean_squared_error: 0.0510\n",
      "Epoch 2/4\n",
      "82224/82224 [==============================] - 5s 55us/sample - loss: 0.0479 - mean_squared_error: 0.0479 - val_loss: 0.0736 - val_mean_squared_error: 0.0736\n",
      "Epoch 3/4\n",
      "82224/82224 [==============================] - 5s 55us/sample - loss: 0.0456 - mean_squared_error: 0.0456 - val_loss: 0.0967 - val_mean_squared_error: 0.0967\n",
      "Epoch 4/4\n",
      "82224/82224 [==============================] - 5s 55us/sample - loss: 0.0440 - mean_squared_error: 0.0440 - val_loss: 0.1223 - val_mean_squared_error: 0.1223\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "#feed the entire thing, start with big batch size 4096 for three epoch, then decrease batch size\n",
    "\n",
    "model=create_model(J,Q,order,input_x,input_y,k_size=4,layer_size=4,nchan_out=8)\n",
    "bs = 4096\n",
    "for epoch in range(2):\n",
    "    model.fit(Sy_train,\n",
    "              y_train_normalized,\n",
    "              epochs=4,\n",
    "              verbose=1,\n",
    "              batch_size=bs,\n",
    "              validation_data = (Sy_val,y_val_normalized),\n",
    "             use_multiprocessing=True)\n",
    "    \n",
    "    bs=bs//2\n",
    "    print(bs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
